@Article{Moss-etal:2013:Astro,
  title     = {High-velocity Clouds in the Galactic All Sky Survey. I. Catalog},
  author    = {Vanessa A. Moss and Naomi M. McClure-Griffiths and Tara Murphy and D. J. Pisano and Jonathan K. Kummerfeld and James R. Curran},
  volume    = {209},
  number    = {1},
  pages     = {12},
  publisher = {IOP Publishing}
  journal   = {The Astrophysical Journal Supplement Series},
  year      = {2013},
  abstract  = {We present a catalogue of high-velocity clouds (HVCs) from the Galactic All Sky Survey (GASS) of southern-sky neutral hydrogen, which has 57 mK sensitivity and 1 km/s velocity resolution and was obtained with the Parkes Telescope. Our catalogue has been derived from the stray-radiation corrected second release of GASS. We describe the data and our method of identifying HVCs and analyse the overall properties of the GASS population. We catalogue a total of 1693 HVCs at declinations < 0 deg, including 1111 positive velocity HVCs and 582 negative velocity HVCs. Our catalogue also includes 295 anomalous velocity clouds (AVCs). The cloud line-widths of our HVC population have a median FWHM of ~19 km/s, which is lower than found in previous surveys. The completeness of our catalogue is above 95\% based on comparison with the HIPASS catalogue of HVCs, upon which we improve with an order of magnitude in spectral resolution. We find 758 new HVCs and AVCs with no HIPASS counterpart. The GASS catalogue will shed an unprecedented light on the distribution and kinematic structure of southern-sky HVCs, as well as delve further into the cloud populations that make up the anomalous velocity gas of the Milky Way.},
  url       = {http://iopscience.iop.org/0067-0049/209/1/12},
  area      = {Other},
}

@InProceedings{Kummerfeld-Klein:2013:EMNLP,
  title     = {Error-Driven Analysis of Challenges in Coreference Resolution},
  author    = {Jonathan K. Kummerfeld and Dan Klein},
  booktitle = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
  shortvenue = {EMNLP},
  month     = {October},
  year      = {2013},
  address   = {Seattle, Washington, USA},
  pages     = {265--277},
  software  = {https://github.com/jkkummerfeld/berkeley-coreference-analyser/},
  abstract  = {Coreference resolution metrics quantify errors but do not analyze them. Here, we consider an automated method of categorizing errors in the output of a coreference system into intuitive underlying error types. Using this tool, we ﬁrst compare the error distributions across a large set of systems, then analyze common errors across the top ten systems, empirically characterizing the major unsolved challenges of the coreference resolution task.},
  area      = {NLP},
}

@InProceedings{Kummerfeld-Tse-Curran-Klein:2013:ACL,
  title     = {An Empirical Examination of Challenges in Chinese Parsing},
  author    = {Jonathan K. Kummerfeld and Daniel Tse and James R. Curran and Dan Klein},
  booktitle = {Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  shortvenue = {ACL (short)},
  address   = {Sofia, Bulgaria},
  pages     = {98--103},
  month     = {August},
  year      = {2013},
  publisher = {Association for Computational Linguistics},
  software  = {https://github.com/jkkummerfeld/berkeley-parser-analyser/},
  url       = {http://www.aclweb.org/anthology/P13-2018},
  abstract  = {Aspects of Chinese syntax result in a distinctive mix of parsing challenges. However, the contribution of individual sources of error to overall difﬁculty is not well understood. We conduct a comprehensive automatic analysis of error types made by Chinese parsers, covering a broad range of error types for large sets of sentences, enabling the ﬁrst empirical ranking of Chinese error types by their performance impact. We also investigate which error types are resolved by using gold part-of-speech tags, showing that improving Chinese tagging only addresses certain error types, leaving substantial outstanding challenges.},
  area      = {NLP},
}

@InProceedings{Kummerfeld-Hall-Curran-Klein:2012:EMNLP,
  title     = {Parser Showdown at the Wall Street Corral: An Empirical Investigation of Error Types in Parser Output},
  author    = {Jonathan K. Kummerfeld and David Hall and James R. Curran and Dan Klein},
  booktitle = {Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
  shortvenue = {EMNLP},
  year      = {2012},
  pages     = {1048--1059},
  month     = {July},
  address   = {Jeju Island, South Korea},
  publisher = {Association for Computational Linguistics},
  software  = {https://github.com/jkkummerfeld/berkeley-parser-analyser/},
  url       = {http://www.aclweb.org/anthology/D12-1096},
  abstract  = {Constituency parser performance is primarily interpreted through a single metric, F-score on WSJ section 23, that conveys no linguistic information regarding the remaining errors.  We classify errors within a set of linguistically meaningful types using tree transformations that repair groups of errors together. We use this analysis to answer a range of questions about parser behaviour, including what linguistic constructions are difficult for state-of-the-art parsers, what types of errors are being resolved by rerankers, and what types are introduced when parsing out-of-domain text.},
  area      = {NLP},
}

@InProceedings{Kummerfeld-Klein-Curran:2012:ACL,
  title     = {Robust Conversion of CCG Derivations to Phrase Structure Trees},
  author    = {Jonathan K. Kummerfeld and Dan Klein and James R. Curran},
  booktitle = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  shortvenue = {ACL (short)},
  year      = {2012},
  pages     = {105--109},
  month     = {July},
  address   = {Jeju Island, South Korea},
  publisher = {Association for Computational Linguistics},
  software  = {https://github.com/jkkummerfeld/berkeley-ccg2pst},
  url       = {http://www.aclweb.org/anthology/P12-2021},
  abstract  = {We propose an improved, bottom-up method for converting CCG derivations into PTB-style phrase structure trees. In contrast with past work (Clark and Curran, 2009), which used simple transductions on category pairs, our approach uses richer transductions attached to single categories. Our conversion preserves more sentences under round-trip conversion (51.1\% vs. 39.6\%) and is more robust. In particular, unlike past methods, ours does not require ad-hoc rules over non-local features, and so can be easily integrated into a parser.},
  area      = {NLP},
}

@InProceedings{Kummerfeld-Bansal-Burkett-Klein:2011:CoNLL,
  title     = {Mention Detection: Heuristics for the OntoNotes annotations},
  author    = {Jonathan K. Kummerfeld and Mohit Bansal and David Burkett and Dan Klein},
  shortvenue = {CoNLL Shared Task},
  booktitle = {Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task},
  year      = {2011},
  pages     = {102--106},
  month     = {June},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  url       = {http://www.aclweb.org/anthology/W11-1916},
  abstract  = {Our submission was a reduced version of the system described in Haghighi and Klein (2010), with extensions to improve mention detection to suit the OntoNotes annotation scheme. Including exact matching mention detection in this shared task added a new and challenging dimension to the problem, particularly for our system, which previously used a very permissive detection method. We improved this aspect of the system by adding filters based on the annotation scheme for OntoNotes and analysis of system behavior on the development set. These changes led to improvements in coreference F-score of 10.06, 5.71, 6.78, 6.63 and 3.09 on the MUC, B3 , Ceaf-e, Ceaf-m and Blanc, metrics, respectively, and a final task score of 47.10.},
  area      = {NLP},
}

@Article{Candelier-etal:2010:PRL,
  title     = {Spatiotemporal Hierarchy of Relaxation Events, Dynamical Heterogeneities, and Structural Reorganization in a Supercooled Liquid},
  author    = {Raphael Candelier and Asaph Widmer-Cooper and Jonathan K. Kummerfeld and Olivier Dauchot and Giulio Biroli and Peter Harrowell and David R. Reichman},
  journal   = {Physical Review Letters},
  volume    = {105},
  number    = {13},
  pages     = {135702},
  numpages  = {4},
  year      = {2010},
  month     = {September},
  doi       = {10.1103/PhysRevLett.105.135702},
  publisher = {American Physical Society},
  url       = {http://prl.aps.org/abstract/PRL/v105/i13/e135702},
  abstract  = {We identify the pattern of microscopic dynamical relaxation for a two-dimensional glass-forming liquid. On short time scales, bursts of irreversible particle motion, called cage jumps, aggregate into clusters. On larger time scales, clusters aggregate both spatially and temporally into avalanches. This propagation of mobility takes place along the soft regions of the systems, which have been identified by computing isoconfigurational Debye-Waller maps. Our results characterize the way in which dynamical heterogeneity evolves in moderately supercooled liquids and reveal that it is astonishingly similar to the one found for dense glassy granular media.},
  area      = {Other},
}

@InProceedings{Honnibal-Kummerfeld-Curran:2010:CoLing,
  title     = {Morphological Analysis Can Improve a CCG Parser for English},
  author    = {Matthew Honnibal and Jonathan K. Kummerfeld and James R. Curran},
  booktitle = {Proceedings of the 23rd International Conference on Computational Linguistics},
  shortvenue = {CoLing},
  year      = {2010},
  pages     = {445--453},
  address   = {Beijing, China},
  month     = {August},
  url       = {http://aclweb.org/anthology/C/C10/C10-2051.pdf},
  abstract  = {Because English is a low morphology language, current statistical parsers tend to ignore morphology and accept some level of redundancy. This paper investigates how costly such redundancy is for a lexicalised grammar such as CCG.

We use morphological analysis to split verb inflectional suffixes into separate tokens, so that they can receive their own lexical categories. We find that this improves accuracy when the splits are based on correct POS tags, but that errors in gold standard or automatically assigned POS tags are costly for the system. This shows that the parser can benefit from morphological analysis, so long as the analysis is correct.},
  area      = {NLP},
}

@InProceedings{Kummerfeld-etal:2010:ACL,
  title     = {Faster Parsing by Supertagger Adaptation},
  author    = {Jonathan K. Kummerfeld and Jessika Roesner and Tim Dawborn and James Haggerty and James R. Curran and Stephen Clark},
  booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
  shortvenue = {ACL},
  month     = {July},
  year      = {2010},
  address   = {Uppsala, Sweden},
  publisher = {Association for Computational Linguistics},
  pages     = {345--355},
  software  = {http://downloads.schwa.org/acl10adapt_fast_news_model.tar.bz2},
  url       = {http://www.aclweb.org/anthology/P/P10/P10-1036.pdf},
  abstract  = {We propose a novel self-training method for a parser which uses a lexicalised grammar and supertagger, focusing on increasing the speed of the parser rather than its accuracy. The idea is to train the supertagger on large amounts of parser output, so that the supertagger can learn to supply the supertags that the parser will eventually choose as part of the highest scoring derivation. Since the supertagger supplies fewer supertags overall, the parsing speed is increased. We demonstrate the effectiveness of the method using a CCG supertagger and parser, obtaining significant speed increases on newspaper text with no loss in accuracy. We also show that the method can be used to adapt the CCG parser to new domains, obtaining accuracy and speed improvements for Wikipedia and biomedical text.},
  area      = {NLP},
}

@PhDThesis{Kummerfeld:2009:Honours,
  title     = {Adaptive Supertagging for Faster Parsing},
  author    = {Jonathan K. Kummerfeld},
  school    = {The University of Sydney},
  year      = {2009},
  address   = {Sydney, Australia},
  abstract  = {Statistical parsers are crucial for tackling the grand challenges of Natural Language Processing. The most effective approaches to these tasks are data driven, but parsers are too slow to be effectively used on large data sets. State-of-the-art parsers generally cannot process more than one sentence a second, and the fastest cannot process more than fifty sentences a second. The situation is even worse when they are applied outside of the domain of their training data. The fastest systems have two components, a parser, which has time complexity O(n3) and a supertagger, which has linear time complexity. By shifting work from the parser to the supertagger we dramatically improve speed.

  This work demonstrates several major novel ideas that improve parsing efficiency. The core idea is that the tags chosen by the parser are gold standard data for its supertagger. This leads to the second surprising conceptual development, that decreasing tagging accuracy can improve parsing performance. To demonstrate these ideas required extensive development of the C&C supertagger, including imple- mentation of more efficient estimation algorithms and parallelisation of the training process. This was particularly challenging as the C&C supertagger is a state-of-the-art high performance system designed with a focus on speed rather than flexibility.

  I was able to significantly improve performance on the standard evaluation corpus by using the parser to generate extremely large new resources for supertagger training. I have also shown that these methods provide significant benefits on another domain, Wikipedia text, without the cost of generating human annotated data sets. These parsing performance gains occur while supertagging accuracy decreases.

  Despite extensive use of supertaggers to improve parsing efficiency there has been no comprehensive study of the interaction between a supertagger and a parser. I present the first systematic exploration of the relationship, show the potential benefits of understanding it, and demonstrate a novel algorithm for optimising the parameters that define it.

  I have constructed models that process newspaper text 86\% faster than previously, and Wikipedia text 30\% faster, without any loss in accuracy and without the aid of extra gold standard resources in either domain. This work will lead directly to improvements in a range of Natural Language Processing tasks by enabling the use of far more parsed data.},
  area      = {NLP},
}

@InProceedings{Kummerfeld-Roesner-Curran:2009:ALTA,
  title     = {Faster parsing and supertagging model estimation},
  author    = {Jonathan K. Kummerfeld and Jessika Roesner and James R. Curran},
  booktitle = {Proceedings of the Australasian Language Technology Association Workshop 2009},
  shortvenue = {ALTA},
  year      = {2009},
  pages     = {62--70},
  address   = {Sydney, Australia},
  month     = {December},
  url       = {http://www.aclweb.org/anthology/U/U09/U09-1009.pdf},
  abstract  = {Parsers are often the bottleneck for data acquisition, processing text too slowly to be widely applied. One way to improve the efficiency of parsers is to construct more confident statistical models. More training data would enable the use of more sophisticated features and also provide more evidence for current features, but gold standard annotated data is limited and expensive to produce.

We demonstrate faster methods for training a supertagger using hundreds of millions of automatically annotated words, constructing statistical models that further constrain the number of derivations the parser must consider. By introducing new features and using an automatically annotated corpus we are able to double parsing speed on Wikipedia and the Wall Street Journal, and gain accuracy slightly when parsing Section 00 of the Wall Street Journal.},
  area      = {NLP},
}

@TechReport{Clark-etal:2009:JHU,
  title     = {Large-Scale Syntactic Processing: Parsing the Web},
  author    = {Stephen Clark and Ann Copestake and James R. Curran and Yue Zhang and Aurelie Herbelot and James Haggerty and Byung-Gyu Ahn and Curt Van Wyk and Jessika Roesner and Jonathan Kummerfeld and Tim Dawborn},
  year      = {2009},
  institution = {Johns Hopkins University},
  abstract  = {Scalable syntactic processing will underpin the sophisticated language technology needed for next generation information access. Companies are already using nlp tools to create web-scale question answering and “semantic search” engines. Massive amounts of parsed web data will also allow the automatic creation of semantic knowledge resources on an unprecedented scale. The web is a challenging arena for syntactic parsing, because of its scale and variety of styles, genres, and domains.

The goals of our workshop were to scale and adapt an existing wide-coverage parser to Wikipedia text; improve the efficiency of the parser through various methods of chart pruning; use self-training to improve the efficiency and accuracy of the parser; use the parsed wiki data for an innovative form of bootstrapping to make the parser both more efficient and more accurate; and finally use the parsed web data for improved disambiguation of coordination structures, using a variety of syntactic and semantic knowledge sources.

The focus of the research was the C&C parser (Clark and Curran, 2007c), a state-of-the-art statistical parser based on Combinatory Categorial Grammar (ccg). The parser has been evaluated on a number of standard test sets achieving state-of-the-art accuracies. It has also recently been adapted successfully to the biomedical domain (Rimell and Clark, 2009). The parser is surprisingly efficient, given its detailed output, processing tens of sentences per second. For web-scale text processing, we aimed to make the parser an order of magnitude faster still. The C&C parser is one of only very few parsers currently available which has the potential to produce detailed, accurate analyses at the scale we were considering.},
  area      = {NLP},
}

@Article{Kummerfeld-Hudson-Harrowell:2008:JPhysChemB,
  title     = {The densest packing of AB binary hard-sphere homogeneous compounds across all size ratios},
  author    = {Jonathan K Kummerfeld and Toby S Hudson and Peter Harrowell},
  journal   = {The Journal of Physical Chemistry B},
  month     = {August},
  year      = {2008},
  volume    = {112},
  issue     = {35},
  pages     = {10773--10776},
  url       = {http://pubs.acs.org/doi/abs/10.1021/jp804953r},
  abstract  = {This paper considers the homogeneous packing of binary hard spheres in an equimolar stoichiometry, and postulates the densest packing at each sphere size ratio. Monte Carlo simulated annealing optimizations are seeded with all known atomic inorganic crystal structures, and the search is performed within the degrees of freedom associated with each homogeneous AB structure type. Structures isopointal to the FeB structure type are found to have the highest packing fraction at all sphere size ratios. The optimized structures match or improve on the best previously demonstrated packings of this type, and show that compound structures can pack more densely than segregated close-packed structures at all radius ratios less than 0.62.},
  area      = {Other},
}

@InProceedings{Kummerfeld-Curran:2008:ALTA,
  title     = {Classification of Verb Particle Constructions with the Google Web1T Corpus},
  author    = {Jonathan K. Kummerfeld and James R. Curran},
  booktitle = {Proceedings of the Australasian Language Technology Association Workshop 2008},
  shortvenue = {ALTA},
  month     = {December},
  year      = {2008},
  address   = {Hobart, Australia},
  pages     = {55--63},
  volume    = {6},
  url       = {http://www.aclweb.org/anthology/U/U08/U08-1008.pdf},
  abstract  = {Manually maintaining comprehensive databases of multi-word expressions, for example Verb-Particle Constructions (VPCs), is infeasible. We describe a new classifier for potential VPCs, which uses information in the Google Web1T corpus to perform a simple linguistic constituency test. Specifically, we consider the fronting test, comparing the frequencies of the two possible orderings of the given verb and particle. Using only a small set of queries for each verb-particle pair, the system was able to achieve an F-score of 78.4\% in our evaluation while processing thousands of queries a second.},
  area      = {NLP},
}
